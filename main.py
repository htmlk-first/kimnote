import os
import tempfile
from typing import List, TypedDict
import streamlit as st
from dotenv import load_dotenv

from retriever_builder import build_retriever
from graph_workflow import create_rag_graph

# 1. í™˜ê²½ ì„¤ì • ë¡œë“œ
load_dotenv()

# Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="UAV ì—°êµ¬ ë³´ì¡° RAG", page_icon="ğŸš")
st.title("UAV ì—°êµ¬ ë³´ì¡° Agentic RAG")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    # ê°„ë‹¨í•œ dict êµ¬ì¡°ë¡œ ê´€ë¦¬: {"role": "user"|"assistant", "content": str}
    st.session_state["messages"] = []

if "rag_app" not in st.session_state:
    st.session_state["rag_app"] = None


# ì±„íŒ… íˆìŠ¤í† ë¦¬ ì¶œë ¥ í•¨ìˆ˜
def print_history():
    for msg in st.session_state["messages"]:
        st.chat_message(msg["role"]).write(msg["content"])


def add_history(role: str, content: str):
    st.session_state["messages"].append({"role": role, "content": content})


# ì‚¬ì´ë“œë°”: íŒŒì¼ ì—…ë¡œë“œ ë° ì„¤ì •
with st.sidebar:
    st.header("ğŸ“‚ ë¬¸ì„œ ì—…ë¡œë“œ")
    uploaded_file = st.file_uploader("ì—°êµ¬ ë…¼ë¬¸(PDF)ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["pdf"])

    if uploaded_file:
        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥ (PyMuPDFLoaderëŠ” ê²½ë¡œê°€ í•„ìš”í•¨)
        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
            tmp_file.write(uploaded_file.getvalue())
            tmp_file_path = tmp_file.name

        # íŒŒì¼ì´ ë³€ê²½ë˜ì—ˆì„ ë•Œë§Œ ì¬ë¹Œë“œ
        if (
            "current_file" not in st.session_state
            or st.session_state["current_file"] != uploaded_file.name
        ):
            retriever = build_retriever(tmp_file_path)
            if retriever:
                st.session_state["rag_app"] = create_rag_graph(retriever)
                st.session_state["current_file"] = uploaded_file.name
                st.success("RAG ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ!")
            else:
                st.error("RAG ì‹œìŠ¤í…œ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. PDF ë‚´ìš©ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")

        # ì„ì‹œ íŒŒì¼ ì‚­ì œ
        os.remove(tmp_file_path)

    st.divider()
    if st.button("ëŒ€í™” ë‚´ìš© ì´ˆê¸°í™”"):
        st.session_state["messages"] = []
        st.rerun()


# ë©”ì¸ í™”ë©´ ë Œë”ë§
print_history()

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if user_input := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):
    # 1. ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€ ë° ì¶œë ¥
    add_history("user", user_input)
    st.chat_message("user").write(user_input)

    # 2. AI ì‘ë‹µ ìƒì„±
    if st.session_state["rag_app"] is None:
        st.warning("ë¨¼ì € ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ PDF íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
    else:
        with st.chat_message("assistant"):
            chat_container = st.empty()

            # LangGraph ì‹¤í–‰ ë° ê²°ê³¼ ìŠ¤íŠ¸ë¦¬ë° ì‹œë®¬ë ˆì´ì…˜
            inputs = {"question": user_input}
            app = st.session_state["rag_app"]

            # ë‹¨ê³„ë³„ ì§„í–‰ ìƒí™© í‘œì‹œ
            with st.status("AIê°€ ìƒê° ì¤‘...", expanded=True) as status:
                final_answer = ""

                # stream()ì„ ì‚¬ìš©í•˜ì—¬ ë…¸ë“œ ì§„í–‰ ìƒí™©ì„ ë³¼ ìˆ˜ ìˆìŒ
                for output in app.stream(inputs):
                    for key, value in output.items():
                        st.write(f"ğŸš© **{key}** ë‹¨ê³„ ì™„ë£Œ")
                        if key == "generate":
                            final_answer = value["generation"]

                status.update(label="ë‹µë³€ ìƒì„± ì™„ë£Œ", state="complete", expanded=False)

            # ìµœì¢… ë‹µë³€ ì¶œë ¥
            chat_container.markdown(final_answer)
            add_history("assistant", final_answer)
